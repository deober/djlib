from __future__ import annotations
from scipy import integrate
import json
import os
from scipy.integrate import cumulative_trapezoid
import numpy as np
import pathlib
import djlib.djlib as dj
from typing import List, Tuple, Dict
import copy
import thermocore.geometry.hull as thull
import pandas as pd

mc_lib_dir = pathlib.Path(__file__).parent.resolve()


def find(lst: List, a: float):
    """Finds the index of an element that matches a specified value.
    Args:
        a(float): The value to search for
    Returns:
        match_list[0](int): The index that a match occurrs, assuming there is only one match.
    """
    print("This is unnecessary. Use np.isclose instead.")
    tolerance = 1e-14
    match_list = [
        i for i, x in enumerate(lst) if np.isclose([x], [a], rtol=tolerance)[0]
    ]
    if len(match_list) == 1:
        return match_list[0]
    elif len(match_list) > 1:
        print("Found more than one match. This is not expected.")
    elif len(match_list) == 0:
        print(
            "\nWARNING: Search value does not match any value in the provided list.\n"
        )


def mc_run_namer(run_params: dict):
    """
    Function to generate a name for a MC simulation based on the run parameters.

    Parameters:
    -----------
    run_params: dict
        Dictionary of run parameters.
        Should include: mu start, stop, & increment; T start, stop, & increment, and supercell transformation matrix.

    Returns:
    --------
    name: str
        Name of the non-lte simulation.
    """
    name = f"mu_{run_params['mu_start']}_{run_params['mu_stop']}T_{run_params['T_start']}_{run_params['T_stop']}"
    return name


def mc_status_updater(run_dir):
    """
    Update status.json in a run directory. Updates to "complete" if results.json exists and is of the right size. Updates to "incomplete" if results.json exists and is of the wrong size.

    Parameters
    ---------
    run_dir: str
        Path to a casm monte carlo run directory. This directory should contain an mc_settings.json file specifying run conditions.

    Returns
    -------
    None. Writes and updates files.
    """
    status_file = os.path.join(run_dir, "status.json")
    settings_file = os.path.join(run_dir, "mc_settings.json")
    length = read_mc_settings(settings_file)[0].shape[0]
    results_file = os.path.join(run_dir, "results.json")

    run_type = None
    if os.path.exists(results_file):
        # Open the file, and check that 'phi_LTE' is a key in the file.
        with open(results_file) as f:
            results = json.load(f)
        if "phi_LTE" in results.keys():
            run_type = "LTE"
        else:
            run_type = "metropolis"

        if run_type == "metropolis":
            results_length = read_mc_results_file(results_file)[0].shape[0]
        elif run_type == "LTE":
            results_length = read_lte_results(results_file)[0].shape[0]
        if results_length == length:
            status = "complete"
        else:
            status = "incomplete"
    else:
        status = "not_submitted"
    with open(status_file, "w") as f:
        json.dump({"status": status}, f, indent=4)


def mc_run_creator(run_params: dict, run_dir: str):
    """
    Creates a grand canonical monte carlo simulation directory, formats necessary settings files,
    writes a status file and writes a run_info.json file, which contains run_params.

    Parameters
    ----------
    run_params: dict
        Dictionary of run parameters.
        Keys should include: mu_start,
                            mu_stop,
                            mu_increment;
                            T_start,
                            T_stop,
                            T_increment,
                            supercell (a transformation matrix applied to the primitive cell),
                            hours (number of hours to run the simulation),
    run_dir: str
        Path to the directory of the mc run, generated by namer function.

    Returns
    -------
    None.
        Creates a directory and writes a mc_settings.json file.
    """
    # Make the run directory
    os.makedirs(run_dir, exist_ok=True)

    # Write the run_params dictionary to a json file called run_info.json
    with open(os.path.join(run_dir, "run_info.json"), "w") as f:
        json.dump(run_params, f)

    # Check that there is a status file called status.json in the run directory.
    # If not, create one, and initialize the status as "not_submitted"
    status_file = os.path.join(run_dir, "status.json")
    if not os.path.exists(status_file):
        with open(status_file, "w") as f:
            json.dump({"status": "not_submitted"}, f)

    # Load and write to the settings file, formatting based on the run_params dictionary.
    mc_settings_file = os.path.join(run_dir, "mc_settings.json")

    mc_template_file = os.path.join(
        mc_lib_dir, "../templates/mc_grand_canonical_template.json"
    )
    with open(mc_template_file) as f:
        mc_template = json.load(f)
    with open(mc_settings_file, "w") as f:
        mc_template["driver"]["initial_conditions"]["param_chem_pot"]["a"] = run_params[
            "mu_start"
        ]
        mc_template["driver"]["final_conditions"]["param_chem_pot"]["a"] = run_params[
            "mu_stop"
        ]
        mc_template["driver"]["incremental_conditions"]["param_chem_pot"][
            "a"
        ] = run_params["mu_increment"]
        mc_template["driver"]["initial_conditions"]["temperature"] = run_params[
            "T_start"
        ]
        mc_template["driver"]["final_conditions"]["temperature"] = run_params["T_stop"]
        mc_template["driver"]["incremental_conditions"]["temperature"] = run_params[
            "T_increment"
        ]
        mc_template["supercell"] = run_params[
            "supercell"
        ]  # TODO: Make sure these keys are how we want them inputted in run_params
        json.dump(mc_template, f, indent=4)

    # Write the slurm submission script to the run directory
    dj.format_slurm_job(
        jobname=mc_run_namer(run_params),
        hours=run_params["hours"],
        user_command="casm monte -s mc_settings.json > mc_results.out",
        output_dir=run_dir,
    )


def mc_lte_run_creator(run_params: dict, run_dir: str):
    """
    Creates a grand canonical monte carlo simulation directory, formats necessary settings files,
    writes a status file and writes a run_info.json file, which contains run_params.

    Parameters
    ----------
    run_params: dict
        Dictionary of run parameters.
        Keys should include: mu_start,
                            mu_stop,
                            mu_increment;
                            T_start,
                            T_stop,
                            T_increment,
                            supercell (a transformation matrix applied to the primitive cell),
                            hours (number of hours to run the simulation),
    run_dir: str
        Path to the directory of the mc run, generated by namer function.

    Returns
    -------
    None.
        Creates a directory and writes a mc_settings.json file.
    """
    # Make the run directory
    os.makedirs(run_dir, exist_ok=True)

    # Write the run_params dictionary to a json file called run_info.json
    with open(os.path.join(run_dir, "run_info.json"), "w") as f:
        json.dump(run_params, f)

    # Check that there is a status file called status.json in the run directory. If not, create one, and initialize the status as "not_submitted"
    status_file = os.path.join(run_dir, "status.json")
    if not os.path.exists(status_file):
        with open(status_file, "w") as f:
            json.dump({"status": "not_submitted"}, f)

    # Load and write to the settings file, formatting based on the run_params dictionary.
    mc_settings_file = os.path.join(run_dir, "mc_settings.json")

    mc_template_file = os.path.join(mc_lib_dir, "../templates/mc_lte_template.json")
    with open(mc_template_file) as f:
        mc_template = json.load(f)
    with open(mc_settings_file, "w") as f:
        mc_template["driver"]["initial_conditions"]["param_chem_pot"]["a"] = run_params[
            "mu_start"
        ]
        mc_template["driver"]["final_conditions"]["param_chem_pot"]["a"] = run_params[
            "mu_stop"
        ]
        mc_template["driver"]["incremental_conditions"]["param_chem_pot"][
            "a"
        ] = run_params["mu_increment"]
        mc_template["driver"]["initial_conditions"]["temperature"] = run_params[
            "T_start"
        ]
        mc_template["driver"]["final_conditions"]["temperature"] = run_params["T_stop"]
        mc_template["driver"]["incremental_conditions"]["temperature"] = run_params[
            "T_increment"
        ]
        mc_template["supercell"] = run_params["supercell"]
        json.dump(mc_template, f, indent=4)

    # Write the slurm submission script to the run directory
    dj.format_slurm_job(
        jobname=mc_run_namer(run_params),
        hours=run_params["hours"],
        user_command="casm monte -s mc_settings.json > mc_results.out",
        output_dir=run_dir,
    )


def mc_run_submitter(run_dir, submit_script_name="submit_slurm.sh"):
    """
    Function to submit a monte carlo simulation to the queue.

    Parameters
    ----------
    run_dir : str
        Path to the directory of the mc run. Should contain a mc_settings.json file, as well as a slurm submission script.
    submit_script_name : str, optional
        Name of the slurm submission script. The default is "submit_slurm.sh".

    Returns
    -------
    None.
        Submits the monte carlo simulation to the queue.
    """
    # Open the status.json file; only submit if the status is "not_submitted"
    status_file = os.path.join(run_dir, "status.json")
    with open(status_file) as f:
        status = json.load(f)["status"]
    if status == "not_submitted":
        dj.submit_slurm_job(run_dir, submit_script_name=submit_script_name)
        with open(os.path.join(run_dir, "status.json"), "w") as f:
            json.dump({"status": "submitted"}, f, indent=4)


def mc_run_parser(run_dir):
    """Loads the results.json file as a dictionary, and returns the dictionary.
    This is mainly intended to be passed to a djlib gridspace manager, which will treat this as an abstracted
    parsing function.

    Parameters
    ----------
    run_dir : str
        Path to the directory of the mc run. Should contain a results.json file.

    Returns
    -------
    results : dict
        Dictionary of the results.json file.
    """
    with open(os.path.join(run_dir, "results.json")) as f:
        results = json.load(f)
    return results


def read_mc_results_file(
    results_file_path: str,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """Function to parse mc results.json files, specifically from semi grand canonical
    simulations (Not LTE; there is a separate function for LTE simulations.)

    This function is obsoleted by the mc_run_parser function, which is intended to be passed to a djlib gridspace manager.

    Parameters
    ----------
        results_file_path(str): Path to the results.json file for the given monte carlo simulation.

    Returns
    -------
        x: np.ndarray
            Vector of compostitions
        b: np.ndarray
            Vector of beta values
        temperature: np.ndarray
            Vecor of temperature values (K)
        potential_energy: np.ndarray:
            Vector of potential energy values (E-mu*x)
    """
    with open(results_file_path) as f:
        results = json.load(f)

    mu = np.array(results["param_chem_pot(a)"])
    x = np.array(results["<comp(a)>"])
    b = np.array(results["Beta"])
    temperature = np.array(results["T"])
    potential_energy = np.array(results["<potential_energy>"])
    formation_energy = np.array(results["<formation_energy>"])
    return (mu, x, b, temperature, potential_energy, formation_energy)


def read_lte_results(
    results_file_path: str,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Takes a lte results.json file and returns outputs from the simulation.

    This function is obsoleted by the mc_run_parser function, which is intended to be passed to a djlib gridspace manager.

    Parameters:
    -----------
    results_file_path: str
        Path to lte results.json file.

    Returns:
    --------
    mu: np.ndarray
        Vector of chemical potentials (species "a")
    b: np.ndarray
        Vector of Beta values (1/Temperature).
    t: np.ndarray
        Vector of temperatures.
    x: np.ndarray
        Vector of compositions.
    pot_eng: np.ndarray
        Vector of phi values (grand canonical potential energy)
    """

    with open(results_file_path) as f:
        results = json.load(f)

    mu = np.array(results["param_chem_pot(a)"])
    b = np.array(results["Beta"])
    t = np.array(results["T"])
    x = np.array(results["gs_comp(a)"])
    semi_grand_canonical_free_energy = np.array(results["phi_LTE"])
    formation_energy = np.array(results["gs_formation_energy"])

    return (mu, b, t, x, semi_grand_canonical_free_energy, formation_energy)


def read_mc_settings(settings_file: str) -> Tuple[np.ndarray, np.ndarray]:
    """
    Function to read chemical potential and temperature values from a mc_settings.json file.

    Parameters
    ----------
    settings_file: str
        Path to mc_settings.json file.

    Returns
    -------
    Tuple[
    mu: np.ndarray
        Vector of chemical potentials (species "a")
    t: np.ndarray
        Vector of temperatures.
        ]
    """
    with open(settings_file) as f:
        settings = json.load(f)

    mu_start = settings["driver"]["initial_conditions"]["param_chem_pot"]["a"]
    mu_stop = settings["driver"]["final_conditions"]["param_chem_pot"]["a"]
    mu_increment = settings["driver"]["incremental_conditions"]["param_chem_pot"]["a"]
    t_start = settings["driver"]["initial_conditions"]["temperature"]
    t_stop = settings["driver"]["final_conditions"]["temperature"]
    t_increment = settings["driver"]["incremental_conditions"]["temperature"]

    if mu_increment != 0:
        mu_length = round(np.abs((mu_start - mu_stop) / mu_increment)) + 1
    else:
        mu_length = 1
    if t_increment != 0:
        t_length = round(np.abs((t_start - t_stop) / t_increment)) + 1
    else:
        t_length = 1

    if mu_length == 1:
        mu_values = np.ones(t_length) * mu_start
    elif mu_length > 1:
        mu_values = np.linspace(mu_start, mu_stop, mu_length)
    if t_length == 1:
        t_values = np.ones(mu_length) * t_start
    elif t_length > 1:
        t_values = np.linspace(t_start, t_stop, t_length)

    return (mu_values, t_values)


def read_superdupercell(mc_settings_file: str) -> List:
    """Function to read mu / temperature values as well as superdupercell from a monte carlo settings.json file.

    Parameters
    ----------
    mc_settings_file: str
        Path to mc_settings.json file.
    Returns
    -------
    superdupercell: List
        Matrix (list of 3 lists) that describes a supercell for the monte carlo simulation.
    """
    with open(mc_settings_file) as f:
        settings = json.load(f)
    superdupercell = settings["supercell"]
    return superdupercell


class lte_run:
    """Class to parse CASM results from Grand Canonical monte carlo low temperature expansion (lte) calculation results.

    Attributes
    ----------
    path: str
        Path to the directory containing the lte results files.

    Methods
    -------
    read_lte_results:
        Function to parse lte results.json files.
    """

    def __init__(self, lte_dir):
        self.path = lte_dir
        self.read_lte_results()
        print(
            "The LTE run class is obsoleted by using the gridspace manager class with associated functions in mc.py and propagation.py."
        )
        print("Please see gridspace manager examples in the djlib examples directory.")

    def read_lte_results(self):
        results_file = os.path.join(self.path, "results.json")
        with open(results_file) as f:
            results = json.load(f)
        self.mu = results["param_chem_pot(a)"]
        self.b = results["Beta"]
        self.t = results["T"]
        self.x = results["<comp(a)>"]
        self.pot_eng = results["<potential_energy>"]
        self.superdupercell = read_superdupercell(
            os.path.join(self.path, "mc_settings.json")
        )


class constant_t_run:
    """Class to parse CASM results from constant temperature Grand Canonical monte carlo calculations.

    Attributes
    ----------
    path: str
        Path to the directory containing the constant temperature results files.

    Methods
    -------
    integrate_constant_temp_grand_canonical:
        Function to integrate the Grand Canonical Free Energy over varying chemical potential at constant temperature.

    """

    def __init__(self, const_t_dir):
        self.path = const_t_dir
        results_file_path = os.path.join(self.path, "results.json")
        (
            self.mu,
            self.x,
            self.b,
            self.t,
            self.pot_eng,
            self.formation_energy,
        ) = read_mc_results_file(results_file_path)
        self.integrate_constant_temp_grand_canonical()
        self.superdupercell = read_superdupercell(
            os.path.join(self.path, "mc_settings.json")
        )
        print(
            "The constant temperature run class is obsoleted by using the gridspace manager class with associated functions in mc.py and propagation.py."
        )
        print("Please see gridspace manager examples in the djlib examples directory.")

    def integrate_constant_temp_grand_canonical(self):
        """Function to integrate across mu values at a constant temperature
        Args:
            x(list): Vector of compostitions
            b(list): Vector of beta values
            potential_energy(list): Vector of potential energy values (E-mu*x)
            mu(list): Vector of mu values

        Returns:
            integrated_potential(list): List of grand canonical free energy values corresponding to a fixed temperature / beta value.
        """
        free_energy_reference = self.pot_eng[0]
        integrated_potential = []
        for index, value in enumerate(self.mu):
            index = index + 1
            if index > 0:
                current_mu = self.mu[0:index]
                current_b = self.b[0:index]
                current_x = self.x[0:index]
                integrated_potential.append(
                    (1 / current_b[-1])
                    * (
                        self.b[0] * free_energy_reference
                        + integrate.simpson((-1 * current_b * current_x), current_mu)
                    )
                )
        self.integ_grand_canonical = np.asarray(integrated_potential)


class heating_run:
    """Class to parse CASM results from heating Grand Canonical monte carlo calculations at constant chemical potential.

    Attributes
    ----------
    path: str
        Path to the directory containing the heating results files.

    Methods
    -------
    get_lte_reference_energy:
        Function to look up the lte reference energy at a given chemical potential, from a lte run object.
    integrate_heating_grand_canonical_from_lte:
        Function to integrate the Grand Canonical Free Energy over varying temperature from the end state of a lte run; all at constant chemical potential.
    """

    def __init__(self, heating_dir, lte_run):
        self.path = heating_dir
        results_file_path = os.path.join(self.path, "results.json")
        (
            self.mu,
            self.x,
            self.b,
            self.t,
            self.pot_eng,
            self.formation_energy,
        ) = read_mc_results_file(results_file_path)
        self.get_lte_reference_energy(lte_run)
        self.integrate_heating_grand_canonical_from_lte()
        self.superdupercell = read_superdupercell(
            os.path.join(self.path, "mc_settings.json")
        )
        print(
            "The heating run class is obsoleted by using the gridspace manager class with associated functions in mc.py and propagation.py."
        )
        print("Please see gridspace manager examples in the djlib examples directory.")

    def get_lte_reference_energy(self, lte_run):
        mu_index = find(lte_run.mu, self.mu[0])
        self.energy_reference = lte_run.pot_eng[mu_index]

    def integrate_heating_grand_canonical_from_lte(self):
        """Function to integrate the grand canonical free energy from monte carlo heating run results.
        Args:
            x(list): Vector of compostitions
            b(list): Vector of beta values
            potential_energy(list): Vector of potential energy values (E-mu*x)
            mu(list): Vector of mu values

        Returns:
            integrated_potential(list): List of grand canonical free energy values corresponding to a fixed mu value.
        """

        self.pot_eng[0] = self.energy_reference

        integrated_potential = []
        for index in range(len(self.b)):
            index = index + 1
            if index > 0:
                current_b = self.b[0:index]
                current_potential_energy = self.pot_eng[0:index]
                integrated_potential.append(
                    (1 / current_b[-1])
                    * (
                        self.b[0] * self.energy_reference
                        + integrate.simpson(current_potential_energy, current_b)
                    )
                )
        self.integ_grand_canonical = np.asarray(integrated_potential)


class cooling_run:
    """Class to parse CASM results from cooling Grand Canonical monte carlo calculations at constant chemical potential.

    Attributes
    ----------
    path: str
        Path to the directory containing the cooling results files.

    Methods
    -------
    get_constant_t_reference_energy:
        Function to look up the lte reference energy at a given chemical potential, from a constant temperature run object.
    """

    def __init__(self, cooling_dir, constant_t_run):
        self.path = cooling_dir
        results_file_path = os.path.join(self.path, "results.json")
        (
            self.mu,
            self.x,
            self.b,
            self.t,
            self.pot_eng,
            self.formation_energy,
        ) = read_mc_results_file(results_file_path)
        self.get_constant_t_reference_energy(constant_t_run)
        self.integrate_cooling_from_const_t_run()
        self.superdupercell = read_superdupercell(
            os.path.join(self.path, "mc_settings.json")
        )
        print(
            "The cooling run class is obsoleted by using the gridspace manager class with associated functions in mc.py and propagation.py."
        )
        print("Please see gridspace manager examples in the djlib examples directory.")

    def get_constant_t_reference_energy(self, constant_t_run):
        mu_index = find(constant_t_run.mu, self.mu[0])
        self.energy_reference = constant_t_run.integ_grand_canonical[mu_index]

    def integrate_cooling_from_const_t_run(self):
        free_energy_reference = self.energy_reference
        integrated_potential = []
        for index, value in enumerate(self.b):
            index = index + 1
            if index > 0:
                current_b = self.b[0:index]
                current_potential_energy = self.pot_eng[0:index]
                integrated_potential.append(
                    (1 / current_b[-1])
                    * (
                        self.b[0] * free_energy_reference
                        + integrate.simpson(current_potential_energy, current_b)
                    )
                )
        self.integ_grand_canonical = np.asarray(integrated_potential)


def find_mc_cooling_lower_convex_hull(sgcmc_project_data_dictionary: dict):
    """Cooling runs can sometimes find new ground states. These manifest as new vertices in the lower convex hull of the cooling runs.
    Finds the lower convex hulls of sgmcmc cooling runs and heating runs, and compares them.
    Also returns the lower convex hulls of the cooling and heating runs. For each point in each lower convex hull,
    returns the composition, formation energy, chemical potential and temperature at that point.

    Parameters
    ----------
    sgcmc_project_data_dictionary : dict
        Dictionary containing the data from all the sgmcmc runs in a project.
        Direct output of djlib.propagation.propagation.propagation_project_parser

    Returns
    -------
    dict
        Dictionary containing the lower convex hulls of the cooling and heating runs:
        Their compositions, formation energies, chemical potentials and temperatures at each point in the lower convex hulls.
    """

    # Integrate the semi grand canonica free energies for the cooling and heating runs.
    integrated_data = full_project_integration(sgcmc_project_data_dictionary)

    # If there is more than one cooling run, find the lower convex hull of the cooling runs.
    # Otherwise, collect the data from the single cooling run.
    cooling_compositions = []
    cooling_formation_energies = []
    cooling_chemical_potentials = []
    cooling_temperatures = []
    for cooling_run in integrated_data["cooling"]:
        cooling_compositions.append(
            cooling_run["<comp(a)>"][np.argmin(cooling_run["T"])]
        )
        cooling_formation_energies.append(
            cooling_run["<formation_energy>"][np.argmin(cooling_run["T"])]
        )
        cooling_chemical_potentials.append(cooling_run["param_chem_pot(a)"])
        cooling_temperatures.append(cooling_run["T"][np.argmin(cooling_run["T"])])

    cooling_compositions = np.array(cooling_compositions)
    cooling_formation_energies = np.array(cooling_formation_energies)
    cooling_chemical_potentials = np.array(cooling_chemical_potentials)
    cooling_temperatures = np.array(cooling_temperatures)
    if len(integrated_data["cooling"]) > 1:
        cooling_hull = thull.full_hull(
            compositions=cooling_compositions.reshape(-1, 1),
            energies=cooling_formation_energies,
        )
        cooling_hull_vertices, _ = thull.lower_hull(cooling_hull)

        hull_vertices_argsort = np.argsort(cooling_compositions[cooling_hull_vertices])
    else:
        cooling_hull = None

    # Collect the same lower convex hull data for the heating runs.
    heating_compositions = []
    heating_formation_energies = []
    heating_chemical_potentials = []
    heating_temperatures = []
    for heating_run in integrated_data["heating"]:
        heating_compositions.append(
            heating_run["<comp(a)>"][np.argmin(heating_run["T"])]
        )
        heating_formation_energies.append(
            heating_run["<formation_energy>"][np.argmin(heating_run["T"])]
        )
        heating_chemical_potentials.append(heating_run["mu"])
        heating_temperatures.append(heating_run["T"][np.argmin(heating_run["T"])])
    heating_compositions = np.array(heating_compositions)
    heating_formation_energies = np.array(heating_formation_energies)
    heating_chemical_potentials = np.array(heating_chemical_potentials)
    heating_temperatures = np.array(heating_temperatures)
    if len(integrated_data["heating"]) > 1:
        heating_hull = thull.full_hull(
            compositions=heating_compositions.reshape(-1, 1),
            energies=heating_formation_energies,
        )
        heating_hull_vertices, _ = thull.lower_hull(heating_hull)
        heating_vertices_argsort = np.argsort(
            heating_compositions[heating_hull_vertices]
        )
    else:
        heating_hull = None

    if cooling_hull is not None:
        cooling_hull_vertices = cooling_hull_vertices[hull_vertices_argsort]
        cooling_compositions = cooling_compositions[cooling_hull_vertices]
        cooling_formation_energies = cooling_formation_energies[cooling_hull_vertices]
        cooling_chemical_potentials = cooling_chemical_potentials[cooling_hull_vertices]
        cooling_temperatures = cooling_temperatures[cooling_hull_vertices]

    if heating_hull is not None:
        heating_hull_vertices = heating_hull_vertices[heating_vertices_argsort]
        heating_compositions = heating_compositions[heating_hull_vertices]
        heating_formation_energies = heating_formation_energies[heating_hull_vertices]
        heating_chemical_potentials = heating_chemical_potentials[heating_hull_vertices]
        heating_temperatures = heating_temperatures[heating_hull_vertices]

    return {
        "cooling": {
            "compositions": cooling_compositions,
            "formation_energies": cooling_formation_energies,
            "chemical_potentials": cooling_chemical_potentials,
            "temperatures": cooling_temperatures,
        },
        "heating": {
            "compositions": heating_compositions,
            "formation_energies": heating_formation_energies,
            "chemical_potentials": heating_chemical_potentials,
            "temperatures": heating_temperatures,
        },
    }


def format_mc_settings(
    superdupercell: list,
    mu_init: float,
    mu_final: float,
    mu_increment: float,
    temp_init: float,
    temp_final: float,
    temp_increment: float,
    output_file: str,
    start_config_path: bool = False,
) -> None:
    """Function to format the CASM monte carlo settings json file file for a monte carlo run.

    Parameters
    ----------
    superdupercell: list
        Tranformation matrix to apply to the CASM project primitive cell. Represented as a list of lists.
    mu_init: float
        Initial chemical potential value.
    mu_final: float
        Final chemical potential value.
    mu_increment: float
        Chemical potential increment value. Sign matters: if positive, it must follow that mu_final > mu_init. If negative, it must follow that mu_final < mu_init.
    temp_init: float
        Initial temperature value.
    temp_final: float
        Final temperature value.
    temp_increment: float
        Temperature increment value. Sign matters: if positive, it must follow that temp_final > temp_init. If negative, it must follow that temp_final < temp_init.
    output_file: str
        Path to the output file.
    start_config_path: str, optional
        Path to the starting configuration file, contained within one of the conditions.* files.

    Returns
    -------
    None.
    """

    templates_path = os.path.join(mc_lib_dir, "../templates")
    # Read template
    with open(os.path.join(templates_path, "mc_grand_canonical_template.json")) as f:
        mc_settings = json.load(f)

    # Write settings
    mc_settings["supercell"] = superdupercell
    mc_settings["driver"]["initial_conditions"]["param_chem_pot"]["a"] = mu_init
    mc_settings["driver"]["initial_conditions"]["temperature"] = temp_init
    mc_settings["driver"]["final_conditions"]["param_chem_pot"]["a"] = mu_final
    mc_settings["driver"]["final_conditions"]["temperature"] = temp_final
    mc_settings["driver"]["incremental_conditions"]["param_chem_pot"][
        "a"
    ] = mu_increment
    mc_settings["driver"]["incremental_conditions"]["temperature"] = temp_increment

    if (start_config_path != False) and (start_config_path != None):
        mc_settings["driver"]["motif"]["configdof"] = start_config_path

    # write settings file
    with open(output_file, "w") as f:
        json.dump(mc_settings, f, indent="")


def run_cooling_from_const_temperature(
    mu_values: np.ndarray,
    mc_cooling_dir: str,
    const_temp_run_dir: str,
    temp_final: float,
    temperature_increment: float,
    job_scheduler: str = "slurm",
    submit_job: bool = False,
) -> None:
    """Runs many cooling Grand Canonical monte carlo calculations; each run is at different chemical potential. The calculations begin at the end state (atomic configuration) of a constant temperature calculation.

    Parameters:
    -----------
    mu_values: np.ndarray
        Array of chemical potential values to run the cooling calculation at.
    mc_cooling_dir: str
        Path to write all cooling calculations to.
    const_temp_run_dir: str
        Path to the directory containing the constant temperature run.
    temp_final: float
        Final temperature value.
    temperature_increment: float
        Temperature increment value. Sign matters: if positive, it must follow that temp_final > temp_init. If negative, it must follow that temp_final < temp_init.
    job_scheduler: str, optional
        Scheduler to use for the job. if not specified, will use slurm.
    submit_job: bool, optional
        Whether to submit the job. If False, will just write the job file. Default is False.
    """

    # read mu values, temperature information from the existing settings file
    (const_t_mu, x, b, temperature_values, potential_energy) = read_mc_results_file(
        os.path.join(const_temp_run_dir, "results.json")
    )
    superdupercell = read_superdupercell(
        os.path.join(const_temp_run_dir, "mc_settings.json")
    )
    # for each mu value, start a cooling run with the condition.# final state as the initial state (condition indexing starts at 0)
    for mu in mu_values:
        # Set up run directory
        run_name = "mu_%.4f_%.4f_T_%d_%d" % (mu, mu, temperature_values[0], temp_final)
        current_dir = os.path.join(mc_cooling_dir, run_name)
        if os.path.isfile(os.path.join(current_dir, "results.json")) == False:
            os.makedirs(current_dir, exist_ok=True)
            os.chdir(current_dir)

            # get const_t_mu index that matches mu
            mu_index = find(const_t_mu, mu)
            # Write settings file
            settings_file = os.path.join(current_dir, "mc_settings.json")
            start_config_path = os.path.join(
                const_temp_run_dir, "conditions.%d" % mu_index, "final_state.json"
            )

            format_mc_settings(
                superdupercell,
                mu,
                mu,
                0,
                temperature_values[0],
                temp_final,
                temperature_increment,
                settings_file,
                start_config_path,
            )

            # Run MC cooling
            if job_scheduler == "slurm":
                user_command = "casm monte -s mc_settings.json > mc_results.out"
                dj.format_slurm_job(
                    jobname="cool_" + run_name,
                    hours=20,
                    user_command=user_command,
                    output_dir=current_dir,
                    delete_submit_script=False,
                )
                if submit_job:
                    dj.submit_slurm_job(current_dir)
            """
            print("Submitting: ", end="")
            print(current_dir)
            os.system("casm monte -s mc_settings.json > mc_results.out &")
            """


def run_heating(
    mc_heating_dir: str,
    mu_values: np.ndarray,
    superdupercell: list,
    temp_init: float,
    temp_final: float,
    temp_increment: float,
    scheduler: str = "slurm",
    submit_job: bool = False,
) -> None:
    """Runs many heating Grand Canonical monte carlo calculations; each run is at different chemical potential.

    Parameters:
    -----------
    mc_heating_dir: str
        Path to write all heating calculations to.
    mu_values: np.ndarray
        Array of chemical potential values to run the heating calculation at.
    superdupercell: list
        Transformation matrix to apply on the CASM project primitive cell. Represented as a list of lists.
    temp_init: float
        Initial temperature value.
    temp_final: float
        Final temperature value.
    temp_increment: float
        Temperature increment value. Sign matters: if positive, it must follow that temp_final > temp_init. If negative, it must follow that temp_final < temp_init.
    scheduler: str, optional
        Scheduler to use for the job. if not specified, will use slurm.
    submit_job: bool, optional
        Whether to submit the job. If False, will just write the job file. Default is False.

    Returns:
    --------
    None.
    """

    for mu_value in mu_values:
        run_name = "mu_%.4f_%.4f_T_%d_%d" % (mu_value, mu_value, temp_init, temp_final)
        current_dir = os.path.join(mc_heating_dir, run_name)

        if os.path.isfile(os.path.join(current_dir, "results.json")) == False:
            os.makedirs(current_dir, exist_ok=True)
            os.chdir(current_dir)

            # Format settings file for this heating run
            settings_file = os.path.join(current_dir, "mc_settings.json")
            format_mc_settings(
                superdupercell,
                mu_value,
                mu_value,
                0,
                temp_init,
                temp_final,
                temp_increment,
                settings_file,
                start_config_path=False,
            )

            # Run MC heating
            user_command = "casm monte -s mc_settings.json > mc_results.out"
            if scheduler == "slurm":
                dj.format_slurm_job(
                    jobname="heat_" + run_name,
                    hours=20,
                    user_command=user_command,
                    output_dir=current_dir,
                    delete_submit_script=False,
                )
                if submit_job:
                    dj.submit_slurm_job(current_dir)
            """
            print("Submitting: ", end="")
            print(current_dir)
            os.system("casm monte -s mc_settings.json > mc_results.out &")
            """


def find_crossing_composition(
    integrated_energies: np.ndarray,
    temperature: np.ndarray,
    x: np.ndarray,
    t_intersect_predict: float,
    energy_intersect_predict: float,
) -> Tuple[float, float]:
    """Given an interpolated point in (energy vs temperature) space, find the closest existing (energy, temperature) and return the corresponding composition x and corresponding temperature.
    Args:
        integrated_energies(ndarray): Vector of integrated energy values.
        temperature(ndarray): Vector of temperature values (K).
        x(ndarray): Vector of composition values.
        t_intersect_predict(float): Interpolated prediction of the free energy crossing temperature between a heating and cooling grand canonical monte carlo simulation.
        energy_intersect_predict(float): Interpolated prediction of the free energy at the crossing temperature between a heating and cooling grand canonical monte carlo simulation.

    Returns:
        Tuple[
            x_at_crossing(float): Composition at the actual coordinates closest to the predicted
            t_at_crossing(float): Temperature (K) at the actual coordinates closest to the predicted
        ]
    """

    temperature_and_energy = np.zeros((len(temperature), 2))
    temperature_and_energy[:, 0] = temperature
    temperature_and_energy[:, 1] = integrated_energies

    prediction_point = np.array([t_intersect_predict, energy_intersect_predict])

    difference = temperature_and_energy - prediction_point

    distance = np.sum(np.abs(difference) ** 2, axis=-1) ** (1 / 2)
    closest_point_index = np.argmin(distance)

    x_at_crossing = x[closest_point_index]
    t_at_crossing = temperature[closest_point_index]
    return (x_at_crossing, t_at_crossing)


def simulation_is_complete(mc_run_dir):
    """Check that a grand canonical monte carlo simulation has finished
    Args:
        mc_run_dir(str): Path to a monte carlo simulation directory.

    Returns:
        simulation_status(bool): simulation is complete (True) or simulation is not complete (False)
    """
    # Check the number of conditions (mu, temp) that should be completed
    # TODO: read the results.json file instead of the number of conditions directories to see if a simulaiton is complete.
    mc_settings_file = os.path.join(mc_run_dir, "mc_settings.json")
    mu_values, temperature_values = read_mc_settings(mc_settings_file)

    target_t_length = temperature_values.shape[0]

    if os.path.isfile(os.path.join(mc_run_dir, "results.json")):
        mu, x, b, temperature, potential_energy = read_mc_results_file(
            os.path.join(mc_run_dir, "results.json")
        )
        if temperature.shape[0] == target_t_length.shape:
            simulation_status = True
        else:
            simulation_status = False
    else:
        print("Cannot find %s" % os.path.join(mc_run_dir, "results.json"))
        simulation_status = False
    return simulation_status


def constant_T_integration(t_const_run_data_dictionary):
    """
    Integrates the grand canonical free energy for a constant temperature run in temperature-chemical potential space.
    Currently Assumes there is one parameterized chemical potential

    Parameters
    ----------
    t_const_run_data_dictionary : dictionary
        Dictionary containing the data from a constant temperature run.

    Returns
    -------
    integrated_free_energy : np.ndarray
        Integrated grand canonical free energy in temperature-chemical potential space.
    """
    # Re-define necessary arrays as np.ndarrays
    free_energy_reference = np.array(t_const_run_data_dictionary["<potential_energy>"])[
        0
    ]

    # Assuming that the composition is very dilute (~ 1e-4), the system entropy should be nearly identical to the ideal solution entropy.
    # Correct for this by adding the entropic contribution to the free energy.
    # For now, enforce that the system is dilute by requiring compositions that are less than 1e-4 or greater than (1-1e-4), but not equal to 0 or 1.
    if (
        t_const_run_data_dictionary["<comp(a)>"][0] != 0
        and t_const_run_data_dictionary["<comp(a)>"][0] != 1
    ):
        if t_const_run_data_dictionary["<comp(a)>"][
            0
        ] < 1e-4 or t_const_run_data_dictionary["<comp(a)>"][0] > (1 - 1e-4):
            k = 8.617333262145e-5  # eV/K
            free_energy_reference = (
                free_energy_reference
                + k
                * t_const_run_data_dictionary["T"][0]
                * (
                    t_const_run_data_dictionary["<comp(a)>"][0]
                    * np.log(t_const_run_data_dictionary["<comp(a)>"][0])
                    + (1 - t_const_run_data_dictionary["<comp(a)>"][0])
                    * np.log(1 - t_const_run_data_dictionary["<comp(a)>"][0])
                )
            )

    mu = np.array(t_const_run_data_dictionary["param_chem_pot(a)"])
    x = np.array(t_const_run_data_dictionary["<comp(a)>"])

    integrated_potential = free_energy_reference - cumulative_trapezoid(x, mu)

    # Using cumulative trapezoid for integration results in a reduction of one data point.
    # because the reference energy is the first data point assuming d\beta is zero, append the reference energy to the beginning of the array.
    integrated_potential = np.insert(integrated_potential, 0, free_energy_reference)

    return np.asarray(integrated_potential)


def constant_chemical_potential_integration(
    run_data_dictionary, integrated_potential_energy_reference
):
    """
    Integrates the grand canonical free energy for a constant chemical potential run in temperature-chemical potential space.
    Requires a reference potential energy from a constant temperature run or LTE run at the same chemical potential
    and initial temperature as the cooling run.
    Currently Assumes there is one parameterized chemical potential

    Notes
    -----
    the potential energy key refers to (E-mu x) in the results.json file output by casm monte

    Parameters
    ----------
    run_data_dictionary : dictionary
        Dictionary containing the data from a constant chemical potential run. (Taken directly from a results.json file output by casm monte)
    integrated_potential_energy_reference : float
        The integrated grand canonical free energy of a constant temperature or LTE run at the same chemical potential and initial temperature as the constant chemical potential run.

    Returns
    -------
    integrated_free_energy : np.ndarray
        Integrated grand canonical free energy in temperature-chemical potential space.
    """
    # Re-define necessary arrays as np.ndarrays
    b = np.array(run_data_dictionary["Beta"])
    potential_energy = np.array(run_data_dictionary["<potential_energy>"])

    # Calculate the grand canonical free energy
    # Cumulative Trapezoid will produce n-1 values, which is why the denominator is b[1:].
    # The first value of the semi grand canonical free energy is known, and is the integrated potential energy reference.
    sgcfe = (
        b[0] * integrated_potential_energy_reference
        + cumulative_trapezoid(
            potential_energy,
            b,
        )
    ) / b[1:]

    # Append integrated potential energy reference to the beginning of the array
    sgcfe = np.insert(sgcfe, 0, integrated_potential_energy_reference)
    return np.array(sgcfe)


def lookup_LTE_reference_energy(T_lookup, LTE_run_data_dictionary):
    """
    To be used with heating integration. Assuming that the LTE run dictionary coresponds to a run at the same chemical potential as the heating run,
    this function finds the LTE reference potential energy at the starting temperature of the heating run.

    Parameters
    ----------
    T_lookup : float
        The temperature at which to find the LTE reference potential energy.
    LTE_run_data_dictionary : dictionary
        Dictionary containing the data from a LTE run. (Taken directly from a results.json file output by casm monte)

    Returns
    -------
    float
        The integrated grand canonical free energy of a LTE run at the temperature T_lookup.
    """
    # Read the phi_LTE (semi grand canonical free energy) from the LTE run data dictionary
    semi_grand_canonical_free_energy = np.array(LTE_run_data_dictionary["phi_LTE"])

    # Find the index of the temperature closest to the temperature at which to find the LTE reference potential energy
    T_index = np.argmin(np.abs(np.array(LTE_run_data_dictionary["T"]) - T_lookup))

    # Return the LTE reference potential energy at the starting temperature of the heating run
    return semi_grand_canonical_free_energy[T_index]


def lookup_constant_T_reference_energy(
    chemical_potential_lookup: float, constant_t_run_dict: dict
) -> float:
    """
    To be used with cooling integration. Assuming that the constant T run dictionary coresponds to a run at the same temperature as the cooling run,
    this function finds the constant T reference potential energy at the starting chemical potential of the cooling run.

    Parameters
    ----------
    chemical_potential_lookup : float
        The chemical potential at which to find the constant T reference potential energy.
    constant_t_run_dict : dictionary
        Dictionary containing the data from a constant temperature run. (Taken directly from a results.json file output by casm monte)

    Returns
    -------
    float
        The integrated grand canonical free energy of a constant temperature run at the chemical potential chemical_potential_lookup.
    """

    # Check if the "integrated_potential_energy" key exists in the constant T run dictionary.
    # If so, load it. Otherwise, calculate it.
    if "integrated_potential_energy" in constant_t_run_dict:
        constant_T_integrated_free_energy = np.array(
            constant_t_run_dict["integrated_potential_energy"]
        )
    else:
        constant_T_integrated_free_energy = constant_T_integration(constant_t_run_dict)

    # Find the index of the chemical potential closest to the chemical potential at which to find the constant T reference potential energy
    chemical_potential_index = np.argmin(
        np.abs(
            np.array(constant_t_run_dict["param_chem_pot(a)"])
            - chemical_potential_lookup
        )
    )

    # Return the constant T reference potential energy at the starting chemical potential of the cooling run
    return constant_T_integrated_free_energy[chemical_potential_index]


def lookup_closest_LTE_run(
    all_LTE_runs: np.ndarray, T_target, chemical_potential_target
):
    """
    Finds the LTE run that is closest to the target chemical potential.
    Returns the closest LTE run dictionary.

    Parameters
    ----------
    all_LTE_runs_list : list
        List of dictionaries containing the data from all LTE runs. (Each dictionary is taken directly from a results.json file output by casm monte)
    T_target : float
        The target temperature.
    chemical_potential_target : float
        The target chemical potential.

    Returns
    -------
    dictionary
        Dictionary containing the data from the LTE run closest to the target temperature and chemical potential.
    """
    # First, find the index of the LTE run that is closest to the target chemical potential
    chemical_potential_index = np.argmin(
        np.abs(
            np.array([run["param_chem_pot(a)"][0] for run in all_LTE_runs])
            - chemical_potential_target
        )
    )

    # Then, check that the target temperature is within the temperature range of the closest LTE run. If it is not, print a warning mesage.
    if not (
        min(all_LTE_runs[chemical_potential_index]["T"])
        <= T_target
        <= max(all_LTE_runs[chemical_potential_index]["T"])
    ):
        print(
            'Warning: Function "lookup_closest_LTE_run": The target temperature is outside the temperature range of the closest LTE run.'
        )

    # Return list index of the LTE run dictionary with the closest chemical potential
    return all_LTE_runs[chemical_potential_index]


def lookup_closest_constant_T_run(
    all_constant_T_runs: np.ndarray, T_target: float, chemical_potential_target: float
):
    """
    Finds the constant T run that is closest to the target temperature, and has an initial chemical potential that is closest to the target chemical potential.
    Returns the list index of the closest constant T run dictionary.

    Parameters
    ----------
    all_constant_T_runs_list : np.ndarray
        List of dictionaries containing the data from all constant temperature runs. (Each dictionary is taken directly from a results.json file output by casm monte)
    T_target : float
        The target temperature.
    chemical_potential_target : float
        The target chemical potential.

    Returns
    -------
    index
        List index of the constant T run dictionary with the closest temperature and chemical potential.
    """
    # If the runs array is not a numpy array, convert it to one
    if not isinstance(all_constant_T_runs, np.ndarray):
        all_constant_T_runs = np.array(all_constant_T_runs)

    # Iterate through all constant T runs, collect the temperatures of all the runs in a list
    all_T = np.array([run["T"][0] for run in all_constant_T_runs])

    # Find the indices of all constant T runs that have a temperature closest to the target temperature
    T_index = np.ravel(
        np.argwhere(np.abs(all_T - T_target) == np.min(np.abs(all_T - T_target)))
    ).astype(int)

    # Of this subset of constant T runs, find the index of the run that has an initial chemical potential closest to the target chemical potential.
    chemical_potential_index = np.argmin(
        np.abs(
            np.array([all_constant_T_runs[i]["param_chem_pot(a)"][0] for i in T_index])
            - chemical_potential_target
        )
    )

    # Return the dictionary of the constant T run with the closest temperature and chemical potential
    return all_constant_T_runs[T_index][chemical_potential_index]


def full_project_integration(project_gcmc_data: dict) -> dict:
    """
    Performs grand canonical free energy integration across all paths (Constant Temperature, LTE, Heating, Cooling) in a casm project.
    Takes a dictionary containing data from all grand canonical Monte Carlo runs in a casm project, and returns the same dictionary after appending 'integrated_potential_energy' keys and values to all runs.

    Parameters
    ----------
    project_gcmc_data : dictionary
        Dictionary containing the data from a full project. (Taken directly from a results.json file output by casm monte)

    Returns
    -------
    project_gcmc_data : dictionary
        The same dictionary, with an added key "integrated_potential_energy" This is equal to the
        integrated grand canonical free energy at each calculated temperature and chemical potential point.
    """

    # Iterate through all constant temperature runs, and append the integrated potential energy to each run dictionary.
    # Also, calculate and append the gibbs free energy to each run dictionary.
    for run_index in range(len(project_gcmc_data["T_const"])):
        project_gcmc_data["T_const"][run_index][
            "integrated_potential_energy"
        ] = constant_T_integration(project_gcmc_data["T_const"][run_index])

        project_gcmc_data["T_const"][run_index]["gibbs"] = project_gcmc_data["T_const"][
            run_index
        ]["integrated_potential_energy"] + np.array(
            project_gcmc_data["T_const"][run_index]["param_chem_pot(a)"]
        ) * np.array(
            project_gcmc_data["T_const"][run_index]["<comp(a)>"]
        )

    # Iterate through all heating runs, look up the LTE reference dictionary to find the reference potential energy, integrate the grand canonical free energy, and append the integrated potential energy to each run dictionary.
    for run_index in range(len(project_gcmc_data["heating"])):
        # Find the chemical potential, and the starting temperature of the heating run
        chemical_potential = project_gcmc_data["heating"][run_index][
            "param_chem_pot(a)"
        ][0]
        T_start = project_gcmc_data["heating"][run_index]["T"][0]

        # Look up the LTE run dictionary that is at this chemical potential
        closest_lte_dict = lookup_closest_LTE_run(
            project_gcmc_data["LTE"], T_start, chemical_potential
        )
        reference_energy = lookup_LTE_reference_energy(T_start, closest_lte_dict)

        # Integrate the grand canonical free energy, and append the integrated potential energy to the heating run dictionary
        project_gcmc_data["heating"][run_index][
            "integrated_potential_energy"
        ] = constant_chemical_potential_integration(
            project_gcmc_data["heating"][run_index], reference_energy
        )

        # Also, calculate and append the gibbs free energy to each run directory
        project_gcmc_data["heating"][run_index]["gibbs"] = project_gcmc_data["heating"][run_index]["integrated_potential_energy"] + np.array(project_gcmc_data["heating"][run_index]["param_chem_pot(a)"]) * np.array(project_gcmc_data["heating"][run_index]["<comp(a)>"])

    # Iterate through all cooling runs, look up the constant temperature reference dictionary to find the reference potential energy, integrate the grand canonical free energy, and append the integrated potential energy to each run dictionary.
    for run_index in range(len(project_gcmc_data["cooling"])):
        # Find the chemical potential, and the starting temperature of the cooling run
        chemical_potential = project_gcmc_data["cooling"][run_index][
            "param_chem_pot(a)"
        ][0]
        T_start = project_gcmc_data["cooling"][run_index]["T"][0]

        # Look up the constant temperature run dictionary that is at this chemical potential
        closest_const_T_dict = lookup_closest_constant_T_run(
            project_gcmc_data["T_const"], T_start, chemical_potential
        )
        reference_energy = lookup_constant_T_reference_energy(
            chemical_potential, closest_const_T_dict
        )

        # Integrate the grand canonical free energy, and append the integrated potential energy to the cooling run dictionary
        project_gcmc_data["cooling"][run_index][
            "integrated_potential_energy"
        ] = constant_chemical_potential_integration(
            project_gcmc_data["cooling"][run_index], reference_energy
        )
        # Also, calculate and append the gibbs free energy to each run directory
        project_gcmc_data["cooling"][run_index]["gibbs"] = project_gcmc_data["cooling"][run_index]["integrated_potential_energy"] + np.array(project_gcmc_data["cooling"][run_index]["param_chem_pot(a)"]) * np.array(project_gcmc_data["cooling"][run_index]["<comp(a)>"])

    return project_gcmc_data


def find_heating_cooling_crossing(
    heating_run_dictionary: dict, cooling_run_dictionary: dict
) -> Tuple[float, float, float, float]:
    """
    Finds the nearest temperature at which the heating and cooling runs cross each other.
    Returns the temperature, composition (heating and cooling), semi grand canonical free energy ("integrated_potential_energy")
    at the crossing point. All returned values are linearly interpolated between calculated data points.

    Parameters
    ----------
    heating_run_dictionary : dictionary
        Dictionary containing the data from a heating run. (Taken directly from a results.json file output by casm monte)
    cooling_run_dictionary : dictionary
        Dictionary containing the data from a cooling run. (Taken directly from a results.json file output by casm monte)

    Returns
    -------
    Tuple[crossing_Temperature:float,           The temperature at which the heating and cooling runs cross each other.
        crossing_sgcfe:float,                   The semi grand canonical free energy at the crossing point.
        crossig_composition_heating:float,      The composition of the heating run at the crossing point.
        crossing_composition_cooling:float      The composition of the cooling run at the crossing point.
        ]
    """
    # Verify that the heating and cooling runs have the same temperature axis.
    # First, check that the length of the temperature axis is the same for both runs.
    assert (
        len(heating_run_dictionary["integrated_potential_energy"])
        == len(heating_run_dictionary["T"])
        == len(cooling_run_dictionary["integrated_potential_energy"])
        == len(cooling_run_dictionary["T"])
        == len(heating_run_dictionary["<comp(a)>"])
        == len(cooling_run_dictionary["<comp(a)>"])
    )

    find_intersection = False
    # IMPORTANT: The spline interpolation requires that the temperature axis be monotonically increasing.
    # The temperature axis is decreasing for the cooling run, so it needs to be flipped.
    # To avoid altering the original dictionary that is passed to the function, a temporary deep copy is made and flipped.
    # This is only necessary for the cooling run because the heating run is already in the correct order.
    if np.allclose(heating_run_dictionary["T"], cooling_run_dictionary["T"]):
        temporary_cooling_T = copy.deepcopy(cooling_run_dictionary["T"])
        temporary_cooling_integrated_free_energy = copy.deepcopy(
            cooling_run_dictionary["integrated_potential_energy"]
        )
        temporary_cooling_composition = copy.deepcopy(
            cooling_run_dictionary["<comp(a)>"]
        )
        find_intersection = True
    else:
        # If the temperature axes arent the same, try swapping the order of temp_cooling and cooling_integrated_free_energy.
        temporary_cooling_T = np.flip(copy.deepcopy(cooling_run_dictionary["T"]))
        temporary_cooling_integrated_free_energy = np.flip(
            copy.deepcopy(cooling_run_dictionary["integrated_potential_energy"])
        )
        temporary_cooling_composition = np.flip(
            copy.deepcopy(cooling_run_dictionary["<comp(a)>"])
        )

        # If the temperature axes still aren't the same, cancel the function.
        if np.allclose(heating_run_dictionary["T"], temporary_cooling_T):
            find_intersection = True
        else:
            print(
                "Heating and cooling run temperature vectors are the same length but do not match. See printout below:\nheating_run  cooling_run"
            )
            for idx in range(len(heating_run_dictionary["T"])):
                print(
                    "%.3f  %.3f" % heating_run_dictionary["T"][idx],
                    cooling_run_dictionary["T"][idx],
                )

    if find_intersection:
        # Take the heating run temperature array.
        # Find the minimum and maximum, and the difference between them.
        # Create a linspace array with double the number of points as the difference between the min and max.
        # Use np.interp to interpolate the heating integrated_potential vs T and the cooling integrated_potential vs T.
        # Also use np.interp to interpolate the heating composition vs T and the cooling composition vs T.
        # Find the index of the minimum difference between the two interpolated integrated_potential vs T arrays.
        # Return the temperature at that index, and the two compositions at that index.

        # Find the minimum and maximum temperature of the heating run
        T_min = np.min(heating_run_dictionary["T"])
        T_max = np.max(heating_run_dictionary["T"])
        T_diff = T_max - T_min

        # Create a linspace array with double the number of points as the difference between the min and max
        T_linspace = np.linspace(T_min, T_max, 2 * round(T_diff))

        # Interpolate the heating and cooling runs to the linspace array
        heating_integrated_potential_interp = np.interp(
            T_linspace,
            heating_run_dictionary["T"],
            heating_run_dictionary["integrated_potential_energy"],
        )
        cooling_integrated_potential_interp = np.interp(
            T_linspace, temporary_cooling_T, temporary_cooling_integrated_free_energy
        )

        heating_composition_interp = np.interp(
            T_linspace, heating_run_dictionary["T"], heating_run_dictionary["<comp(a)>"]
        )
        cooling_composition_interp = np.interp(
            T_linspace, temporary_cooling_T, temporary_cooling_composition
        )

        # Find the index of the minimum difference between the two interpolated integrated_potential vs T arrays
        crossing_index = np.argmin(
            abs(
                heating_integrated_potential_interp
                - cooling_integrated_potential_interp
            )
        )

        # Return the interpolated temperature, semi grand canonical free energy, heating composition and cooling composition at the crossing point
        return (
            T_linspace[crossing_index],
            heating_integrated_potential_interp[crossing_index],
            heating_composition_interp[crossing_index],
            cooling_composition_interp[crossing_index],
        )


def find_constant_T_crossing(
    constant_T_dict_1: dict, constant_T_dict_2: dict
) -> Tuple[float, float, float, float]:
    """
    Finds the nearest chemical potential at which the two constant temperature runs cross each other in (chemical_potential, Temperature) space.
    Returns the composition at the crossing point

    Parameters
    ----------
    constant_T_dict_1 : dictionary
        Dictionary for the first constant temperature run
    constant_T_dict_2 : dictionary
        Dictionary for the second constant temperature run

    Returns
    -------
    Tuple[
    mu_intersect_predict : float
        Chemical potential at the intersection point
    energy_intersect_predict : float
        Semi grand canonical free energy ("integrated_potential_energy") at the intersection point.
    composition_intersect_predict_1 : float
        Composition at the intersection point, for the first constant temperature run.
    composition_intersect_predict_2 : float
        Composition at the intersection point, for the second constant temperature run.
        ]
    """

    # Assert that the chemical potentials are the same
    # TODO: This will fail if the chemical potentials are not exactly the same, though that is not necessary. We just need to have the
    # chemical potential ranges overlap.
    if not np.allclose(
        np.sort(constant_T_dict_1["param_chem_pot(a)"]),
        np.sort(constant_T_dict_2["param_chem_pot(a)"]),
    ):
        print(
            "Chemical potential arrays between the two constant T runs are not identical."
        )
        print(
            "It is possible that the chemical potential arrays have overlapping values. If the values overlap, it is still not guaranteed that the two runs will cross each other."
        )
        print(
            "The program will continue, but the results may be incorrect. Please examine carefully."
        )

    # Ensure that all data is sorted by chemical potential
    mu_1 = np.array(constant_T_dict_1["param_chem_pot(a)"])[
        np.argsort(constant_T_dict_1["param_chem_pot(a)"])
    ]
    gc_free_energy_1 = constant_T_dict_1["integrated_potential_energy"][
        np.argsort(constant_T_dict_1["param_chem_pot(a)"])
    ]
    x_1 = np.array(constant_T_dict_1["<comp(a)>"])[
        np.argsort(constant_T_dict_1["param_chem_pot(a)"])
    ]

    mu_2 = np.array(constant_T_dict_2["param_chem_pot(a)"])[
        np.argsort(constant_T_dict_2["param_chem_pot(a)"])
    ]
    gc_free_energy_2 = constant_T_dict_2["integrated_potential_energy"][
        np.argsort(constant_T_dict_2["param_chem_pot(a)"])
    ]
    x_2 = np.array(constant_T_dict_2["<comp(a)>"])[
        np.argsort(constant_T_dict_2["param_chem_pot(a)"])
    ]

    # Find the minimum and maximum chemical potentials, and create a linspace array between the minimum and maximum values incrementing by 0.001.
    mu_min = np.min([np.min(mu_1), np.min(mu_2)])
    mu_max = np.max([np.max(mu_1), np.max(mu_2)])
    mu_diff = round(np.abs(mu_max - mu_min))
    mu_linspace = np.linspace(mu_min, mu_max, mu_diff * 1000)

    # Create a piecewise linear interpolation of the  semi grand canonical free energy vs chemical potential for each run using np.interp.
    # Also create a piecewise linear interpolation of the composition vs chemical potential for each run using np.interp.
    gc_free_energy_1_interp = np.interp(mu_linspace, mu_1, gc_free_energy_1)
    gc_free_energy_2_interp = np.interp(mu_linspace, mu_2, gc_free_energy_2)
    x_1_interp = np.interp(mu_linspace, mu_1, x_1)
    x_2_interp = np.interp(mu_linspace, mu_2, x_2)

    # Find the index of the minimum difference between the two interpolated semi grand canonical free energy functions
    min_diff_index = np.argmin(abs(gc_free_energy_1_interp - gc_free_energy_2_interp))

    # Return the chemical potential, integrated grand canonical free energy, and two compositions at the minimum difference index
    return (
        mu_linspace[min_diff_index],
        gc_free_energy_1_interp[min_diff_index],
        x_1_interp[min_diff_index],
        x_2_interp[min_diff_index],
    )


def order_disorder_crossing_points(project_gcmc_data: dict) -> List[dict]:
    """
    Calculates the points in (composition,Temperature) space where free energy curves cross, indicating an order-disorder transition.
    Currently, only works for a binary system.

    Parameters
    ----------
    project_gcmc_data : dictionary
        Dictionary containing the GCMC data for the project.
        This includes all four types of calculation paths: Constant Temperature, LTE, Heating and Cooling.

    Returns
    -------
    crossing_points:list
        List of dictionaries containing the temperature, composition, chemical potential and integrated semi grand canonical free energy at each order-disorder transition.
        Also includes the path type that the transition was calculated from. Options are 'fixed_T' or 'fixed_chemical_potential'.
        For each crossing point, there is one temperature and two compositions. The temperature and both compositions are returned.
    """
    # Run full project integration on the data to ensure that all integrated free energies are calculated.
    project_gcmc_data = full_project_integration(project_gcmc_data)

    # Initialize the list of crossing points
    crossing_points = []

    # First, check for order-disorder transitions in the constant temperature runs.
    # Constant temperature runs come in pairs at a given temperature. Find and pair them.
    constant_T_runs = project_gcmc_data["T_const"]
    constant_T_temperatures = np.unique([run["T"][0] for run in constant_T_runs])
    constant_T_run_pairs = []
    for T in constant_T_temperatures:
        temporary_pair = [run for run in constant_T_runs if run["T"][0] == T]
        if len(temporary_pair) > 1:
            constant_T_run_pairs.append(temporary_pair)

    # Iterate through the pairs of constant temperature runs and find the crossing points.
    # Append the crossing points to the list of crossing points as a dictionary.
    for pair in constant_T_run_pairs:
        (
            mu_intersect_predict,
            energy_intersect_predict,
            x_intersect_1,
            x_intersect_2,
        ) = find_constant_T_crossing(pair[0], pair[1])
        crossing_points.append(
            {
                "T": pair[0]["T"][0],
                "x_1": x_intersect_1,
                "x_2": x_intersect_2,
                "mu": mu_intersect_predict,
                "free_energy": energy_intersect_predict,
                "path_type": "fixed_T",
            }
        )

    # Next, check for order-disorder transitions in the fixed chemical potential runs.
    # Fixed chemical potential runs come in pairs at a given chemical potential. Find and pair them.
    heating_runs = project_gcmc_data["heating"]
    cooling_runs = project_gcmc_data["cooling"]
    fixed_chem_potential_runs = heating_runs + cooling_runs

    # First, round all chemical potentials to 6 decimal places to avoid floating point errors
    fixed_chem_potential_chem_pots = np.unique(
        [np.round(run["param_chem_pot(a)"][0], 6) for run in fixed_chem_potential_runs]
    )
    fixed_chem_potential_run_pairs = []
    for mu in fixed_chem_potential_chem_pots:
        fixed_chem_potential_run_pairs.append(
            [
                run
                for run in fixed_chem_potential_runs
                if np.isclose(run["param_chem_pot(a)"][0], mu)
            ]
        )

    # It is possible for there to be more than one pair of heating-cooling runs at a given
    # chemical potential. If this is the case, remove the duplicate runs from pairs.
    for index, entry in enumerate(fixed_chem_potential_run_pairs):
        if len(entry) != 2:
            print(
                "Pair of runs at chemical potential",
                entry[0]["param_chem_pot(a)"][0],
                "has",
                len(entry),
                "runs. Removing duplicates.",
            )
            if len(entry) > 2 and len(entry) % 2 == 0:
                # There are likely two heating and two cooling runs at the same chemical potential.
                # If two runs have the same chemical potential and first temperature,
                # they are the same run. Remove one of the runs.
                temporary_temperature_list = []
                temporary_entry = []
                for run in entry:
                    if run["T"][0] not in temporary_temperature_list:
                        temporary_temperature_list.append(run["T"][0])
                        temporary_entry.append(run)
                fixed_chem_potential_run_pairs[index] = temporary_entry
            else:
                print(
                    "There are more than two runs at ",
                    entry[0]["param_chem_pot(a)"][0],
                    "and the number of runs is not even. Please check the data.",
                )
    # Iterate through the pairs of fixed chemical potential runs and find the crossing points.
    # Append the crossing points to the list of crossing points as a dictionary.
    for pair in fixed_chem_potential_run_pairs:
        (
            T_intersect_predict,
            energy_intersect_predict,
            x_intersect_predict_heating,
            x_intersect_predict_cooling,
        ) = find_heating_cooling_crossing(pair[0], pair[1])
        crossing_points.append(
            {
                "T": T_intersect_predict,
                "x_1": x_intersect_predict_heating,
                "x_2": x_intersect_predict_cooling,
                "mu": pair[0]["param_chem_pot(a)"][0],
                "free_energy": energy_intersect_predict,
                "path_type": "fixed_chemical_potential",
            }
        )

    # TODO: This function currently returns predicted crossing points that are interpolated from the data.
    # If it is necessary to only use actual calculated points, this can be done using the "find_crossing_composition" function in this module.
    return crossing_points


def load_updated_data_to_pandas_dataframe(updated_data, run_offset_index=False):
    """
    Takes the dictionary of Monte Carlo data (for a single set of Monte Carlo) and returns a pandas dataframe with the following columns:
    
    T: Temperature
    param_chem_pot(a): Chemical potential
    comp(a)_heating: Composition of the heating run at the given T and mu
    comp(a)_cooling: Composition of the cooling run at the given T and mu
    comp(a)_T_const_lr: Composition of the T_const run at the given T and mu, where the T_const run is run from left to right (increasing mu)
    comp(a)_T_const_rl: Composition of the T_const run at the given T and mu, where the T_const run is run from right to left (decreasing mu)
    phi_heating: Integrated potential energy of the heating run at the given T and mu
    phi_cooling: Integrated potential energy of the cooling run at the given T and mu
    phi_T_const_lr: Integrated potential energy of the T_const run at the given T and mu, where the T_const run is run from left to right (increasing mu)
    phi_T_const_rl: Integrated potential energy of the T_const run at the given T and mu, where the T_const run is run from right to left (decreasing mu)
    phi_lowest: Lowest integrated potential energy of all four methods at the given T and mu
    method: Method that has the lowest integrated potential energy at the given T and mu

    Parameters
    ----------

    updated_data : dictionary
        Dictionary of Monte Carlo data (for a single set of Monte Carlo) - Should contain the integrated potential energy for each run
    run_offset_index : int, optional
        The index of the T_const runs that separates the left->right runs from the right-> left runs. If not provided, the default is half the length of the T_const runs.

    Returns
    -------

    phi_data : pandas dataframe
        Dataframe containing the data from the Monte Carlo data dictionary, with the columns described above.
    """

    if not run_offset_index:
        run_offset_index = int(len(updated_data['T_const'])/2)
    print(run_offset_index)

    phi_data = pd.DataFrame()
    T_range = updated_data['heating'][0]['T']
    mu_range = updated_data['T_const'][run_offset_index]['param_chem_pot(a)']
    for i,T in enumerate(T_range):
        if updated_data['T_const'][i]['T'][0] == T and updated_data['T_const'][i+run_offset_index]['T'][0] == T:
            for j,mu in enumerate(mu_range):
                # find the value of phi (integrated_chemical_potential) for each method at the given T and mu
                if updated_data['heating'][j]['T'][i] == T:
                    phi_heating = updated_data['heating'][j]['integrated_potential_energy'][i]
                else:
                    print("Didn't match T for heating ", T, updated_data['heating'][j]['T'][i])
                if updated_data['cooling'][j]['T'][len(T_range)-1-i] == T:
                    phi_cooling = updated_data['cooling'][j]['integrated_potential_energy'][len(T_range)-1-i]
                else:
                    print("Didn't match T for cooling ", T, updated_data['cooling'][j]['T'][len(T_range)-1-i])
                # TODO: Make this smart and actually have it figure out which direction the t_const_runs are going instead of assuming it R->L at lower indices and vice versa
                if updated_data['T_const'][i]['param_chem_pot(a)'][len(mu_range)-1-j] == mu:
                    phi_T_const_rl = updated_data['T_const'][i]['integrated_potential_energy'][len(mu_range)-1-j]
                else:
                    print("Didn't match mu for T_const_rl ", mu, updated_data['T_const'][i]['param_chem_pot(a)'][len(mu_range)-1-j])
                if updated_data['T_const'][i+run_offset_index]['param_chem_pot(a)'][j] == mu:
                    phi_T_const_lr = updated_data['T_const'][i+run_offset_index]['integrated_potential_energy'][j]
                else:
                    print("Didn't match mu for T_const_lr ", mu, updated_data['T_const'][i+run_offset_index]['param_chem_pot(a)'][j])
                # get method that has lowest phi
                phi_min = min(phi_heating, phi_cooling, phi_T_const_lr, phi_T_const_rl)
                method = 'heating' if phi_min == phi_heating else 'cooling' if phi_min == phi_cooling else 'T_const_lr' if phi_min == phi_T_const_lr else 'T_const_rl'
                temp_dict = {'T': T, 
                            'param_chem_pot(a)': mu,
                            'comp(a)_heating': updated_data['heating'][j]['<comp(a)>'][i], 
                            'comp(a)_cooling': updated_data['cooling'][j]['<comp(a)>'][len(T_range)-1-i], 
                            'comp(a)_T_const_lr': updated_data['T_const'][i+run_offset_index]['<comp(a)>'][j], 
                            'comp(a)_T_const_rl': updated_data['T_const'][i]['<comp(a)>'][len(mu_range)-1-j], 
                            'phi_heating': phi_heating, 
                            'phi_cooling': phi_cooling, 
                            'phi_T_const_lr': phi_T_const_lr, 
                            'phi_T_const_rl': phi_T_const_rl, 
                            'phi_lowest': phi_min,
                            'method': method
                            }
                phi_data = phi_data.append(temp_dict, ignore_index=True)
        else:
            print("Didn't match T for T_const ", T, updated_data['T_const'][i]['T'][0], updated_data['T_const'][i+run_offset_index]['T'][0])
        
    return phi_data